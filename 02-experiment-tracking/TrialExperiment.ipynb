{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa342bf",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b47fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import uuid\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0b581",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_handling(filepath):\n",
    "    df = pd.read_parquet(filepath)\n",
    "    # print(f\"Data loaded from {filepath}...\")\n",
    "\n",
    "    # Data Preprocessing\n",
    "    # print(\"Preprocessing data...\\n\")\n",
    "    # print(f\"Initial shape: {df.shape}\")\n",
    "    # print(f\"Number of columns: {df.shape[1]}\\n\")\n",
    "\n",
    "    df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "    df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    # print(f\"Standard deviation of the trips duration: {round(df.duration.std(), 2)}\\n\")\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    numerical = []\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    # Anomaly Handling\n",
    "    # print(\"Handling outliers...\\n\")\n",
    "    initial_rows = df.shape[0]\n",
    "    df = df[((df.duration >= 1) & (df.duration <= 60))]\n",
    "    final_rows = df.shape[0]\n",
    "    \n",
    "    # print(f\"Initial records: {initial_rows}\")\n",
    "    # print(f\"Final records: {final_rows}\")\n",
    "    # print(f\"Fraction of the records after outliers handling: {100-(100*(initial_rows - final_rows)/final_rows):.2f}%\\n\")\n",
    "\n",
    "    # print(\"----------------------\\n\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d0905",
   "metadata": {},
   "source": [
    "## ML Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bfd3a0",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01950391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df_train, df_val):\n",
    "    # Feature Engineering\n",
    "    # print(\"Feature engineering...\\n\")\n",
    "\n",
    "    target = 'duration'\n",
    "    numerical = []\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    mlflow.log_param(\"target\", target)\n",
    "    mlflow.log_param(\"numerical_columns\", numerical)\n",
    "    mlflow.log_param(\"categorical_columns\", categorical)\n",
    "\n",
    "    # One-hot encoding\n",
    "    # print(\"One-hot encoding...\\n\")\n",
    "    \n",
    "    dv = DictVectorizer()\n",
    "    X_train = dv.fit_transform(df_train[categorical + numerical].to_dict(orient='records'))\n",
    "    y_train = df_train[target].values\n",
    "    mlflow.log_param(\"X_train_shape\", X_train.shape)\n",
    "    mlflow.log_param(\"y_train_shape\", y_train.shape)\n",
    "    mlflow.log_param(\"X_train_columns\", X_train.shape[1])\n",
    "\n",
    "    # print(f\"Number of features: {len(dv.get_feature_names_out())}\")\n",
    "    # print(f\"Training shape: {X_train.shape}\")    \n",
    "    # print(f\"Dimensionality of this matrix (number of columns): {X_train.shape[1]}\\n\")\n",
    "\n",
    "    X_val = dv.transform(df_val[categorical + numerical].to_dict(orient='records'))\n",
    "    y_val = df_val[target].values\n",
    "    mlflow.log_param(\"X_val_shape\", X_val.shape)\n",
    "    mlflow.log_param(\"y_val_shape\", y_val.shape)\n",
    "    mlflow.log_param(\"X_val_columns\", X_val.shape[1])\n",
    "    \n",
    "    # print(f\"Validation shape: {X_val.shape}\")\n",
    "    # print(f\"Dimensionality of this matrix (number of columns): {X_val.shape[1]}\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, dv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb11d6",
   "metadata": {},
   "source": [
    "### Linear Regression Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f12698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegression_modelDev(X_train, y_train, X_val, y_val, dv):\n",
    "    # Training the model\n",
    "    # print(\"Training the model...\")\n",
    "    mlflow.set_tag(\"model\", \"linear_regression\")\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    mlflow.log_param(\"model_type\", type(model).__name__)\n",
    "    mlflow.log_param(\"model_name\", model.__class__.__name__)\n",
    "    mlflow.log_param(\"model_params\", model.get_params())\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test = model.predict(X_train)\n",
    "    train_rmse = root_mean_squared_error(y_train, y_test)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    # print(f\"Training RMSE: {train_rmse:.2f}\\n\")\n",
    "\n",
    "    # Model Validation\n",
    "    # print(\"Model Validation...\")\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    val_rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "\n",
    "    # print(f\"Validation RMSE: {val_rmse:.2f}\\n\")\n",
    "    \n",
    "    # Save the model\n",
    "    with open('models/testTracked_LRmodel.bin', 'wb') as f_out:\n",
    "        mlflow.log_artifact('models/testTracked_LRmodel.bin')\n",
    "        pickle.dump((dv, model), f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed399dd",
   "metadata": {},
   "source": [
    "### XGBoost Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ac3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost_modelDev(X_train, y_train, X_val, y_val, dv):\n",
    "    # Training the model\n",
    "    print(\"Training the XGBoost model...\\n\")\n",
    "    \n",
    "    mlflow.set_tag(\"model\", \"XGBoost\")\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    def objective(params):\n",
    "        with mlflow.start_run(nested=True):\n",
    "            # Tags specific to this evaluation\n",
    "            mlflow.set_tag(\"evaluation_id\", str(uuid.uuid4())[:8])  # Optional: unique ID for this evaluation\n",
    "            mlflow.set_tag(\"evaluation_step\", \"hyperparameter_tuning\")\n",
    "            \n",
    "            # Tag specific parameter ranges\n",
    "            if params['learning_rate'] < 0.1:\n",
    "                mlflow.set_tag(\"learning_rate_range\", \"low\")\n",
    "            else:\n",
    "                mlflow.set_tag(\"learning_rate_range\", \"high\")\n",
    "\n",
    "            # Log parameters within this child run\n",
    "            mlflow.log_params(params)\n",
    "            \n",
    "            booster = xgb.train(\n",
    "                params = params,\n",
    "                dtrain = xgb.DMatrix(X_train, label=y_train),\n",
    "                num_boost_round = 1000,\n",
    "                evals = [(xgb.DMatrix(X_val, label=y_val), 'validation')],\n",
    "                early_stopping_rounds = 50\n",
    "            )\n",
    "\n",
    "            y_pred = booster.predict(xgb.DMatrix(X_val))\n",
    "            val_rmse = root_mean_squared_error(y_val, y_pred)\n",
    "            \n",
    "            # Log the metric within this child run\n",
    "            mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "            print(f\"Validation RMSE: {val_rmse:.2f}\\n\")\n",
    "        \n",
    "        return {'loss': val_rmse, 'status': STATUS_OK}\n",
    "\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -3, 0), # exp(-3), exp(0) -> [0.05, 1]\n",
    "        'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "        'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "        'objective': 'reg:linear',\n",
    "        'seed': 42,\n",
    "    }\n",
    "\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=50,\n",
    "        trials=Trials()\n",
    "    )\n",
    "\n",
    "    print(f\"Best hyperparameters: {best}\\n\")\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in best.items()})\n",
    "\n",
    "    # # Train the final model with the best hyperparameters\n",
    "    # best_params = {k: int(v) if k == 'n_estimators' or k == 'max_depth' else v for k, v in best.items()}\n",
    "    # model = xgb.XGBRegressor(**best_params)\n",
    "    \n",
    "    # model.fit(X_train, y_train)\n",
    "    \n",
    "    # # Model Validation\n",
    "    # print(\"Model Validation...\")\n",
    "\n",
    "    # y_pred = model.predict(X_val)\n",
    "    # val_rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    # mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "\n",
    "    # print(f\"Validation RMSE: {val_rmse:.2f}\\n\")\n",
    "    \n",
    "    # # Save the model\n",
    "    # with open('models/testTracked_XBGmodel.bin', 'wb') as f_out:\n",
    "    #     mlflow.log_artifact('models/testTracked_XBGmodel.bin')\n",
    "    #     pickle.dump((dv, model), f_out)\n",
    "    # print(\"Model saved successfully...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf390cd",
   "metadata": {},
   "source": [
    "## Integrated All Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.xgboost\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"TrialExperimentNYC_Taxi\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"developer\", \"sutiwas-jitsopak\")\n",
    "\n",
    "    mlflow.log_param(\"train-data-path\", \"../01-intro/data/yellow_tripdata_2023-01.parquet\")\n",
    "    mlflow.log_param(\"valid-data-path\", \"../01-intro/data/yellow_tripdata_2023-02.parquet\")\n",
    "\n",
    "    # Data Loading, Preprocessing and Anomaly Handling\n",
    "    df_train = read_and_handling(\"../01-intro/data/yellow_tripdata_2023-01.parquet\")\n",
    "    df_val = read_and_handling(\"../01-intro/data/yellow_tripdata_2023-02.parquet\")\n",
    "    mlflow.log_param(\"train_shape\", df_train.shape)\n",
    "    mlflow.log_param(\"valid_shape\", df_val.shape)\n",
    "    \n",
    "    # ML Model Development: Feature Engineering\n",
    "    X_train, y_train, X_val, y_val, dv = feature_engineering(df_train, df_val)\n",
    "\n",
    "    # ML Model Development: Linear Regression\n",
    "    linearRegression_modelDev(X_train, y_train, X_val, y_val, dv)\n",
    "    print(\"Linear Regression Model training and evaluation completed.\\n\")\n",
    "\n",
    "    # ML Model Development:\n",
    "    ## Hyperparameter tuning \n",
    "    # XGBoost_modelDev(X_train, y_train, X_val, y_val, dv)\n",
    "\n",
    "    ## Final model training\n",
    "    # mlflow.set_tag(\"model\", \"XGBoost\")\n",
    "    # mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "\n",
    "    # params = {\n",
    "    #     'learning_rate': 0.9846137718216238,\n",
    "    #     'max_depth': 90,\n",
    "    #     'min_child_weight': 7.97363247466668,\n",
    "    #     'objective': 'reg:linear',\n",
    "    #     'reg_alpha': 0.05098434242156559,\n",
    "    #     'reg_lambda': 0.0025084928043955963,\n",
    "    #     'seed': 42,\n",
    "    # }\n",
    "\n",
    "    # mlflow.xgboost.autolog()\n",
    "    # booster = xgb.train(\n",
    "    #     params=params,\n",
    "    #     dtrain=xgb.DMatrix(X_train, label=y_train),\n",
    "    #     num_boost_round=1000,\n",
    "    #     evals=[(xgb.DMatrix(X_val, label=y_val), 'validation')],\n",
    "    #     early_stopping_rounds=50\n",
    "    # )\n",
    "\n",
    "    print(\"XGBoost Model training and evaluation completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "482b8eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[929]\tvalidation-rmse:5.17709\n",
      "[930]\tvalidation-rmse:5.17699\n",
      "[931]\tvalidation-rmse:5.17695\n",
      "[932]\tvalidation-rmse:5.17694\n",
      "[933]\tvalidation-rmse:5.17693\n",
      "[934]\tvalidation-rmse:5.17701\n",
      "[935]\tvalidation-rmse:5.17684\n",
      "[936]\tvalidation-rmse:5.17664\n",
      "[937]\tvalidation-rmse:5.17680\n",
      "[938]\tvalidation-rmse:5.17678\n",
      "[939]\tvalidation-rmse:5.17679\n",
      "[940]\tvalidation-rmse:5.17680\n",
      "[941]\tvalidation-rmse:5.17697\n",
      "[942]\tvalidation-rmse:5.17679\n",
      "[943]\tvalidation-rmse:5.17667\n",
      "[944]\tvalidation-rmse:5.17661\n",
      "[945]\tvalidation-rmse:5.17677\n",
      "[946]\tvalidation-rmse:5.17665\n",
      "[947]\tvalidation-rmse:5.17667\n",
      "[948]\tvalidation-rmse:5.17668\n",
      "[949]\tvalidation-rmse:5.17665\n",
      "[950]\tvalidation-rmse:5.17665\n",
      "[951]\tvalidation-rmse:5.17666\n",
      "[952]\tvalidation-rmse:5.17683\n",
      "[953]\tvalidation-rmse:5.17686\n",
      "[954]\tvalidation-rmse:5.17667\n",
      "[955]\tvalidation-rmse:5.17664\n",
      "[956]\tvalidation-rmse:5.17647\n",
      "[957]\tvalidation-rmse:5.17666\n",
      "[958]\tvalidation-rmse:5.17664\n",
      "[959]\tvalidation-rmse:5.17660\n",
      "[960]\tvalidation-rmse:5.17656\n",
      "[961]\tvalidation-rmse:5.17656\n",
      "[962]\tvalidation-rmse:5.17655\n",
      "[963]\tvalidation-rmse:5.17654\n",
      "[964]\tvalidation-rmse:5.17654\n",
      "[965]\tvalidation-rmse:5.17650\n",
      "[966]\tvalidation-rmse:5.17649\n",
      "[967]\tvalidation-rmse:5.17648\n",
      "[968]\tvalidation-rmse:5.17649\n",
      "[969]\tvalidation-rmse:5.17667\n",
      "[970]\tvalidation-rmse:5.17667\n",
      "[971]\tvalidation-rmse:5.17655\n",
      "[972]\tvalidation-rmse:5.17655\n",
      "[973]\tvalidation-rmse:5.17668\n",
      "[974]\tvalidation-rmse:5.17648\n",
      "[975]\tvalidation-rmse:5.17647\n",
      "[976]\tvalidation-rmse:5.17647\n",
      "[977]\tvalidation-rmse:5.17641\n",
      "[978]\tvalidation-rmse:5.17635\n",
      "[979]\tvalidation-rmse:5.17635\n",
      "[980]\tvalidation-rmse:5.17632\n",
      "[981]\tvalidation-rmse:5.17654\n",
      "[982]\tvalidation-rmse:5.17658\n",
      "[983]\tvalidation-rmse:5.17635\n",
      "[984]\tvalidation-rmse:5.17634\n",
      "[985]\tvalidation-rmse:5.17631\n",
      "[986]\tvalidation-rmse:5.17632\n",
      "[987]\tvalidation-rmse:5.17629\n",
      "[988]\tvalidation-rmse:5.17616\n",
      "[989]\tvalidation-rmse:5.17621\n",
      "[990]\tvalidation-rmse:5.17619\n",
      "[991]\tvalidation-rmse:5.17624\n",
      "[992]\tvalidation-rmse:5.17640\n",
      "[993]\tvalidation-rmse:5.17620\n",
      "[994]\tvalidation-rmse:5.17634\n",
      "[995]\tvalidation-rmse:5.17616\n",
      "[996]\tvalidation-rmse:5.17614\n",
      "[997]\tvalidation-rmse:5.17608\n",
      "[998]\tvalidation-rmse:5.17612\n",
      "[999]\tvalidation-rmse:5.17613\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.9846137718216238,\n",
    "    'max_depth': 90,\n",
    "    'min_child_weight': 7.97363247466668,\n",
    "    'objective': 'reg:linear',\n",
    "    'reg_alpha': 0.05098434242156559,\n",
    "    'reg_lambda': 0.0025084928043955963,\n",
    "    'seed': 42,\n",
    "    }\n",
    "\n",
    "mlflow.xgboost.autolog()\n",
    "booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=xgb.DMatrix(X_train, label=y_train),\n",
    "    num_boost_round=1000,\n",
    "    evals=[(xgb.DMatrix(X_val, label=y_val), 'validation')],\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "with open('models/testTracked_XBGmodel.bin', 'wb') as f_out:\n",
    "    mlflow.log_artifact('models/testTracked_XBGmodel.bin')\n",
    "    pickle.dump((dv, booster), f_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tracking-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
